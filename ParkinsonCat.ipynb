{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from skimage.feature import hog\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['healthy', 'parkinson']\n",
    "categories = ['testing','training']\n",
    "im_types = ['spiral','wave']\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "base_dir = os.path.join(cwd, 'parkinsons-drawings')\n",
    "\n",
    "# Walk through the image directory\n",
    "# Read in images as grayscale and resave\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for name in files:\n",
    "        image = cv2.imread(os.path.join(root, name), 0)\n",
    "        cv2.imwrite(os.path.join(root,name), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Walk through image directory\n",
    "# Rescale all spiral drawings to 256x256 and all wave to 256x128 for \n",
    "# consistent size to be used as features\n",
    "for im_type in im_types:\n",
    "    direc = os.path.join(base_dir, im_type)\n",
    "    if im_type == 'spiral':\n",
    "        imsize = (256,256)\n",
    "    else:\n",
    "        imsize = (256,128)\n",
    "    for root, dirs, files in os.walk(direc):\n",
    "        for name in files:\n",
    "            image = cv2.imread(os.path.join(root,name),0)\n",
    "            resized = cv2.resize(image, imsize)\n",
    "            cv2.imwrite(os.path.join(root,name), resized)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pickleData():\n",
    "    \n",
    "    # Create lists of dictionaries for each image type\n",
    "    spiral_training = []\n",
    "    direc = os.path.join(base_dir, 'spiral', 'training')\n",
    "\n",
    "    for root, dirs, files in os.walk(direc, followlinks=False):\n",
    "        for name in files:\n",
    "            image = cv2.imread(os.path.join(root,name),0)\n",
    "            label = name[3]\n",
    "            tdict = {'Desc': 'Spiral', 'Label': label, 'Image': image}\n",
    "            spiral_training.append(tdict)\n",
    "    \n",
    "    spiral_testing = []\n",
    "    direc = os.path.join(base_dir, 'spiral', 'testing')\n",
    "\n",
    "    for root, dirs, files in os.walk(direc, followlinks=False):\n",
    "        for name in files:\n",
    "            image = cv2.imread(os.path.join(root,name),0)\n",
    "            label = name[3]\n",
    "            tdict = {'Desc': 'Spiral', 'Label': label, 'Image': image}\n",
    "            spiral_testing.append(tdict)  \n",
    "\n",
    "    wave_training = []\n",
    "    direc = os.path.join(base_dir, 'wave', 'training')\n",
    "\n",
    "    for root, dirs, files in os.walk(direc, followlinks=False):\n",
    "        for name in files:\n",
    "            image = cv2.imread(os.path.join(root,name),0)\n",
    "            label = name[3]\n",
    "            tdict = {'Desc': 'Wave', 'Label': label, 'Image': image}\n",
    "            wave_training.append(tdict)   \n",
    "        \n",
    "    wave_testing = []\n",
    "    direc = os.path.join(base_dir, 'wave', 'testing')\n",
    "\n",
    "    for root, dirs, files in os.walk(direc, followlinks=False):\n",
    "        for name in files:\n",
    "            image = cv2.imread(os.path.join(root,name),0)\n",
    "            label = name[3]\n",
    "            tdict = {'Desc': 'Wave', 'Label': label, 'Image': image}\n",
    "            wave_testing.append(tdict)    \n",
    "\n",
    "    # Pickle datasets\n",
    "    pickle.dump(spiral_training, open('spiral_training.p','wb'))\n",
    "    pickle.dump(spiral_testing, open('spiral_testing.p','wb'))\n",
    "    pickle.dump(wave_training, open('wave_training.p','wb'))\n",
    "    pickle.dump(wave_testing, open('wave_testing.p','wb'))\n",
    "\n",
    "    \n",
    "def unpickleData():\n",
    "    spiral_training = pickle.load(open('spiral_training.p','rb'))\n",
    "    spiral_testing = pickle.load(open('spiral_testing.p','rb'))\n",
    "    wave_training = pickle.load(open('wave_training.p','rb'))\n",
    "    wave_testing = pickle.load(open('wave_testing.p','rb'))\n",
    "    return spiral_training, spiral_testing, wave_training, wave_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickleData()\n",
    "spiral_training, spiral_testing, wave_training, wave_testing = unpickleData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractXy(mylist):\n",
    "    X = []\n",
    "    y = []\n",
    "    for entry in mylist:\n",
    "        X.append(entry.get(\"Image\"))\n",
    "        y.append(entry.get(\"Label\"))\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "Xspiral, yspiral = extractXy(spiral_training)\n",
    "yspiral = [1 if (x == 'H' or x == 1) else 0 for x in yspiral]\n",
    "print(yspiral)\n",
    "#print(Xspiral[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HogTransformer from https://kapernikov.com/tutorial-image-classification-with-scikit-learn/\n",
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                pixels_per_cell=(16,16),\n",
    "                cells_per_block=(3,3),\n",
    "                block_norm = 'L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                      orientations = self.orientations,\n",
    "                      pixels_per_cell = self.pixels_per_cell,\n",
    "                      cells_per_block = self.cells_per_block,\n",
    "                      block_norm = self.block_norm,\n",
    "                      feature_vector=True)\n",
    "        try:\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "    \n",
    "    \n",
    "hogify = HogTransformer(pixels_per_cell=(8,8),\n",
    "                        cells_per_block=(1,1),\n",
    "                        orientations=9, \n",
    "                        block_norm='L2-Hys')\n",
    "scalify = StandardScaler()\n",
    "\n",
    "Xspiral_hog = hogify.fit_transform(Xspiral)\n",
    "Xspiral_prepared = scalify.fit_transform(Xspiral_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\nSVCpipeline = Pipeline([\\n    ('hogify', HogTransformer(pixels_per_cell=(8,8),\\n                        cells_per_block=(1,1),\\n                        orientations=9, \\n                        block_norm='L2-Hys')\\n    ),\\n    ('scalify', StandardScaler()),\\n    ('classify', SVC(random_state=42))\\n])\\n\\nparam_grid = [\\n    {'hogify__orientations': [9],\\n    'hogify__cells_per_block': [(3,3)],\\n    'hogify__pixels_per_cell': [(18,18)],\\n    'classify__C': [8e-4, 9e-4, 1e-3, 1.5e-3],\\n    'classify__kernel': ['rbf','linear']\\n    }\\n]\\n\\n\\ngrid_search = GridSearchCV(SVCpipeline,\\n                          param_grid,\\n                          cv=3,\\n                          n_jobs=-1,\\n                           scoring='recall',\\n                           verbose=1,\\n                           return_train_score=True)\\n\\ngrid_res = grid_search.fit(Xspiral, yspiral)\\n\\nprint(grid_res.best_estimator_)\\nprint(grid_res.best_score_)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "\n",
    "SVCpipeline = Pipeline([\n",
    "    ('hogify', HogTransformer(pixels_per_cell=(8,8),\n",
    "                        cells_per_block=(1,1),\n",
    "                        orientations=9, \n",
    "                        block_norm='L2-Hys')\n",
    "    ),\n",
    "    ('scalify', StandardScaler()),\n",
    "    ('classify', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {'hogify__orientations': [9],\n",
    "    'hogify__cells_per_block': [(3,3)],\n",
    "    'hogify__pixels_per_cell': [(18,18)],\n",
    "    'classify__C': [8e-4, 9e-4, 1e-3, 1.5e-3],\n",
    "    'classify__kernel': ['rbf','linear']\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(SVCpipeline,\n",
    "                          param_grid,\n",
    "                          cv=3,\n",
    "                          n_jobs=-1,\n",
    "                           scoring='recall',\n",
    "                           verbose=1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_res = grid_search.fit(Xspiral, yspiral)\n",
    "\n",
    "print(grid_res.best_estimator_)\n",
    "print(grid_res.best_score_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "[False False False False False  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      " False  True False  True  True  True]\n",
      "Accuracy:  0.7333333333333333\n",
      "Recall:  0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  12   3\n",
       "1   5  10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SVCpipeline = Pipeline([\n",
    "    ('hogify', HogTransformer()\n",
    "    ),\n",
    "    ('scalify', StandardScaler()),\n",
    "    ('classify', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "clf = SVCpipeline.fit(Xspiral, yspiral)\n",
    "\n",
    "Xspiraltest, yspiraltest = extractXy(spiral_testing)\n",
    "yspiraltest = [1 if (x == 'H' or x == 1) else 0 for x in yspiraltest]\n",
    "print(yspiraltest)\n",
    "\n",
    "yspiralpred = clf.predict(Xspiraltest)\n",
    "print(yspiralpred)\n",
    "\n",
    "\n",
    "print(np.array(yspiralpred == yspiraltest))\n",
    "print('Accuracy: ', np.sum(yspiralpred == yspiraltest)/len(yspiraltest))\n",
    "print('Recall: ', recall_score(yspiraltest, yspiralpred))\n",
    "\n",
    "\n",
    "confusion_spiral = confusion_matrix(yspiraltest, yspiralpred)\n",
    "df = pd.DataFrame(confusion_spiral)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True False  True  True  True  True\n",
      "  True  True False  True  True  True]\n",
      "Accuracy:  0.8\n",
      "Recall:  0.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  12   3\n",
       "1   3  12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVCpipelineOptimized = Pipeline([\n",
    "    ('hogify', HogTransformer(pixels_per_cell=(18,18),\n",
    "                        cells_per_block=(3,3),\n",
    "                        orientations=9, \n",
    "                        block_norm='L2-Hys')\n",
    "    ),\n",
    "    ('scalify', StandardScaler()),\n",
    "    ('classify', SVC(random_state=42,  C = 0.0008, kernel = 'linear'))\n",
    "])\n",
    "\n",
    "op_clf = SVCpipelineOptimized.fit(Xspiral, yspiral)\n",
    "\n",
    "yspiraltest = [1 if (x == 'H' or x == 1) else 0 for x in yspiraltest]\n",
    "\n",
    "yspiralpred = op_clf.predict(Xspiraltest)\n",
    "\n",
    "\n",
    "print(np.array(yspiralpred == yspiraltest))\n",
    "print('Accuracy: ', np.sum(yspiralpred == yspiraltest)/len(yspiraltest))\n",
    "print('Recall: ', recall_score(yspiraltest, yspiralpred))\n",
    "\n",
    "confusion_spiral = confusion_matrix(yspiraltest, yspiralpred)\n",
    "df = pd.DataFrame(confusion_spiral)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 252, 252, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               62980352  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 63,016,193\n",
      "Trainable params: 63,016,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import keras_metrics\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(5,5),activation='relu',\n",
    "                       input_shape=(256,256,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(units=64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.utils import to_categorical\\n\\nmodel.compile(loss='binary_crossentropy',\\n             optimizer='rmsprop',\\n             metrics=['accuracy'])\\n\\n\\n\\nXspiral, yspiral = extractXy(spiral_training)\\n\\nXspiraltest, yspiraltest = extractXy(spiral_testing)\\n\\nXspiral = Xspiral.reshape(72, 256, 256, 1)\\nXspiral = Xspiral.astype('float32') / 255\\n\\nyspiral = [1 if (x == 'H' or x == 1) else 0 for x in yspiral]\\n\\n\\n\\nmodel.fit(Xspiral, yspiral,\\n         epochs=42,\\n         verbose=1\\n         )\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "Xspiral, yspiral = extractXy(spiral_training)\n",
    "\n",
    "Xspiraltest, yspiraltest = extractXy(spiral_testing)\n",
    "\n",
    "Xspiral = Xspiral.reshape(72, 256, 256, 1)\n",
    "Xspiral = Xspiral.astype('float32') / 255\n",
    "\n",
    "yspiral = [1 if (x == 'H' or x == 1) else 0 for x in yspiral]\n",
    "\n",
    "\n",
    "\n",
    "model.fit(Xspiral, yspiral,\n",
    "         epochs=42,\n",
    "         verbose=1\n",
    "         )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nXspiraltest = Xspiraltest.reshape(30, 256, 256, 1)\\nyspiraltest = [1 if (x == 'H' or x == 1) else 0 for x in yspiraltest]\\nprint(yspiraltest)\\n\\ntest_loss, test_acc = model.evaluate(Xspiraltest, yspiraltest)\\nprint(test_loss)\\nprint(test_acc)\\n\\npred = model.predict_classes(Xspiraltest)\\nprint(pred)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Xspiraltest = Xspiraltest.reshape(30, 256, 256, 1)\n",
    "yspiraltest = [1 if (x == 'H' or x == 1) else 0 for x in yspiraltest]\n",
    "print(yspiraltest)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(Xspiraltest, yspiraltest)\n",
    "print(test_loss)\n",
    "print(test_acc)\n",
    "\n",
    "pred = model.predict_classes(Xspiraltest)\n",
    "print(pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# parameters:\n",
    "# ypred = model's prediction\n",
    "# ytest = true values\n",
    "def getMetrics(pred, ytest):\n",
    "    cm = confusion_matrix(ytest, pred).flatten()\n",
    "    (tn, fp, fn, tp) = cm\n",
    "    metrics = {}\n",
    "\n",
    "    metrics[\"accuracy\"] = (tp + tn) / float(cm.sum())\n",
    "    metrics[\"precision\"] = tp / float((tp + fp))\n",
    "    metrics[\"recall\"] = tp / float((tp + fn))\n",
    "    metrics[\"f1\"] = f1_score(ytest, pred)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def getLearningCurve(model, title, x, y):\n",
    "    plt.grid()\n",
    "    plt.title(title)\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, x, y)\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    \n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color = 'r', label = 'Train')\n",
    "    plt.plot(train_sizes, test_mean, 'o-', color = 'g', label = 'Test')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xspiraltest_prepared' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8f733a5f5f8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myspiral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXspiraltest_prepared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetMetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myspiraltest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n{x} estimators\\n-----\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xspiraltest_prepared' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "Xspiral, yspiral = extractXy(spiral_training)\n",
    "\n",
    "Xspiraltest, yspiraltest = extractXy(spiral_testing)\n",
    "\n",
    "ForestProcessing = Pipeline([\n",
    "    ('hog', HogTransformer(pixels_per_cell=(8,8),\n",
    "                            cells_per_block=(1,1),\n",
    "                            orientations=9,\n",
    "                            block_norm='L2-Hys')\n",
    "    ),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "def trainForest(newX, n_estimators):\n",
    "    model = RandomForestClassifier(n_estimators = n_estimators)\n",
    "    model.fit(newX, yspiral)\n",
    "    return model \n",
    "\n",
    "\n",
    "\n",
    "estimators = [100, 500, 1000]\n",
    "hogged = hogify.fit_transform(Xspiraltest)\n",
    "newX = ForestProcessing.fit_transform(Xspiral)\n",
    "\n",
    "for n in estimators:\n",
    "    model = RandomForestClassifier(n_estimators=n)\n",
    "    model.fit(newX, yspiral)\n",
    "    pred = model.predict(Xspiraltest_prepared)\n",
    "    metrics = getMetrics(pred, yspiraltest)\n",
    "    print(\"\\n{x} estimators\\n-----\".format(x=n))\n",
    "    getLearningCurve(model, \"Random forest: {x} estimators\".format(x=n), newX, yspiral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
